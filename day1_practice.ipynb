{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShomaTani/lecture-ai-engineering/blob/master/day1_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSpnWBP5ELSI"
      },
      "source": [
        "# å®Ÿè·µæ¼”ç¿’ Day 1ï¼šstreamlitã¨FastAPIã®ãƒ‡ãƒ¢\n",
        "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ä»¥ä¸‹ã®å†…å®¹ã‚’å­¦ç¿’ã—ã¾ã™ã€‚\n",
        "\n",
        "- å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ç’°å¢ƒè¨­å®š\n",
        "- Hugging Faceã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸStreamlitã®ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒª\n",
        "- FastAPIã¨ngrokã‚’ä½¿ç”¨ã—ãŸAPIã®å…¬é–‹æ–¹æ³•\n",
        "\n",
        "æ¼”ç¿’ã‚’å§‹ã‚ã‚‹å‰ã«ã€HuggingFaceã¨ngrokã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã—ã€\n",
        "ãã‚Œãã‚Œã®APIãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "\n",
        "\n",
        "æ¼”ç¿’ã®æ™‚é–“ã§ã¯ã€ä»¥ä¸‹ã®3ã¤ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’é †ã«èª¬æ˜ã—ã¾ã™ã€‚\n",
        "\n",
        "1. 01_streamlit_UI\n",
        "2. 02_streamlit_app\n",
        "3. 03_FastAPI\n",
        "\n",
        "2ã¤ç›®ã‚„3ã¤ç›®ã‹ã‚‰ã§ã‚‚å§‹ã‚ã‚‰ã‚Œã‚‹æ§˜ã«ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½œæˆã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "å¾©ç¿’ã®éš›ã«ã‚‚ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’å½¹ç«‹ã¦ã¦ã„ãŸã ã‘ã‚Œã°ã¨æ€ã„ã¾ã™ã€‚\n",
        "\n",
        "### æ³¨æ„äº‹é …\n",
        "ã€Œ02_streamlit_appã€ã¨ã€Œ03_FastAPIã€ã§ã¯ã€GPUã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
        "\n",
        "ã“ã‚Œã‚‰ã‚’å®Ÿè¡Œã™ã‚‹éš›ã¯ã€Google Colabç”»é¢ä¸Šã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ã€Œç·¨é›†ã€â†’ ã€Œãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®è¨­å®šã€\n",
        "\n",
        "ã€Œãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ãƒ¼ã€ã®é …ç›®ã®ä¸­ã‹ã‚‰ã€ã€ŒT4 GPUã€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã€ŒCPUã€ã«ãªã£ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhtHkJOgELSL"
      },
      "source": [
        "# ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼ˆ1~3å…±æœ‰ï¼‰\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-FjBp4MMQHM"
      },
      "source": [
        "GitHubã‹ã‚‰æ¼”ç¿’ç”¨ã®ã‚³ãƒ¼ãƒ‰ã‚’Cloneã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIXMavdDEP8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe94e2b-8c57-4f63-c546-e58037abb03d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lecture-ai-engineering'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Total 52 (delta 0), reused 0 (delta 0), pack-reused 52 (from 1)\u001b[K\n",
            "Receiving objects: 100% (52/52), 83.21 KiB | 5.55 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/matsuolab/lecture-ai-engineering.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC8n7yZ_vs1K"
      },
      "source": [
        "å¿…è¦ãªAPIãƒˆãƒ¼ã‚¯ãƒ³ã‚’.envã«è¨­å®šã—ã¾ã™ã€‚\n",
        "\n",
        "ã€Œlecture-ai-engineering/day1ã€ã®é…ä¸‹ã«ã€ã€Œ.env_templateã€ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "éš ã—ãƒ•ã‚¡ã‚¤ãƒ«ã®ãŸã‚è¡¨ç¤ºã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ç”»é¢å·¦å´ã®ã‚ã‚‹ã€ç›®ã®ã‚¢ã‚¤ã‚³ãƒ³ã®ã€Œéš ã—ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡¨ç¤ºã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ã€Œ.env_templateã€ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã€Œ.envã€ã«å¤‰æ›´ã—ã¾ã™ã€‚ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªä¸­èº«ã«ãªã£ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "\n",
        "```\n",
        "HUGGINGFACE_TOKEN=\"hf-********\"\n",
        "NGROK_TOKEN=\"********\"\n",
        "```\n",
        "ãƒ€ãƒ–ãƒ«ã‚¯ã‚ªãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§å›²ã¾ã‚ŒãŸæ–‡å­—åˆ—ã‚’Huggingfaceã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã€ngrokã®èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã§æ›¸ãå¤‰ãˆã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ãã‚Œãã‚Œã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒä½œæˆæ¸ˆã¿ã§ã‚ã‚Œã°ã€ä»¥ä¸‹ã®URLã‹ã‚‰ãã‚Œãã‚Œã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã§ãã¾ã™ã€‚\n",
        "\n",
        "- Huggingfaceã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³\n",
        "https://huggingface.co/docs/hub/security-tokens\n",
        "\n",
        "- ngrokã®èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³\n",
        "https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "æ›¸ãæ›ãˆãŸã‚‰ã€ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã®PCã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ã€Œ01_streamlit_UIã€ã‹ã‚‰ã€Œ02_streamlit_appã€ã¸é€²ã‚€éš›ã«ã€CPUã‹ã‚‰GPUã®åˆ©ç”¨ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ãŸã‚ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒä¸€åº¦åˆ‡ã‚Œã¦ã—ã¾ã„ã¾ã™ã€‚\n",
        "\n",
        "ãã®éš›ã«ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®šã—ãŸã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã¯å†ä½œæˆã™ã‚‹ã“ã¨ã«ãªã‚‹ã®ã§ã€ãã®æ‰‹é–“ã‚’æ¸›ã‚‰ã™ãŸã‚ã«ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãŠãã¨è‰¯ã„ã§ã™ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py1BFS5RqcSS"
      },
      "source": [
        "ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ç’°å¢ƒå¤‰æ•°ã¨ã—ã¦è¨­å®šã—ã¾ã™ã€‚æ¬¡ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã€æœ€çµ‚çš„ã«ã€ŒTrueã€ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚Œã°ã†ã¾ãèª­ã¿è¾¼ã‚ã¦ã„ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvEowFfg5lrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14430c3e-f313-4f89-d532-1d49d4e29bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "/content/lecture-ai-engineering/day1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "%cd /content/lecture-ai-engineering/day1\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os0Yk6gaELSM"
      },
      "source": [
        "# 01_streamlit_UI\n",
        "\n",
        "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€Œ01_streamlit_UIã€ã«ç§»å‹•ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S28XgOm0ELSM"
      },
      "outputs": [],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/01_streamlit_UI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVp-aEIkELSM"
      },
      "source": [
        "å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBe41LFiELSN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyw6VHaTELSN"
      },
      "source": [
        "ngrokã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€èªè¨¼ã‚’è¡Œã„ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYw1q0iXELSN"
      },
      "outputs": [],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RssTcD_IELSN"
      },
      "source": [
        "ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-E7ucR6ELSN"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"å…¬é–‹URL: {public_url}\")\n",
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbYyXVFjELSN"
      },
      "source": [
        "å…¬é–‹URLã®å¾Œã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹URLã«ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã¨ã€streamlitã®UIãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚\n",
        "\n",
        "app.pyã®ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã•ã‚Œã¦ã„ã‚‹ç®‡æ‰€ã‚’ç·¨é›†ã™ã‚‹ã“ã¨ã§ã€UIãŒã©ã®æ§˜ã«å¤‰åŒ–ã™ã‚‹ã‹ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚\n",
        "\n",
        "streamlitã®å…¬å¼ãƒšãƒ¼ã‚¸ã«ã¯ã€ã‚®ãƒ£ãƒ©ãƒªãƒ¼ãƒšãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "\n",
        "streamlitã‚’ä½¿ã†ã¨pythonã¨ã„ã†ä¸€ã¤ã®è¨€èªã§ã‚ã£ã¦ã‚‚ã€æ§˜ã€…ãªUIã‚’å®Ÿç¾ã§ãã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã¨æ€ã„ã¾ã™ã€‚\n",
        "\n",
        "https://streamlit.io/gallery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmtP5GLOELSN"
      },
      "source": [
        "å¾Œç‰‡ä»˜ã‘ã¨ã—ã¦ã€ä½¿ã†å¿…è¦ã®ãªã„ngrokã®ãƒˆãƒ³ãƒãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ek9QgahELSO"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-T8tFpyELSO"
      },
      "source": [
        "# 02_streamlit_app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqogFQKnELSO"
      },
      "source": [
        "\n",
        "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€Œ02_streamlit_appã€ã«ç§»å‹•ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeEjlJ7uELSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0541a974-d06b-4084-a13a-fc76177a1028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lecture-ai-engineering/day1/02_streamlit_app\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/02_streamlit_app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XUH2AstELSO"
      },
      "source": [
        "å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDqvI4V3ELSO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO31umGZELSO"
      },
      "source": [
        "ngrokã¨huggigfaceã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€èªè¨¼ã‚’è¡Œã„ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPxTiEWQELSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "535f8ead-7872-4fc3-9eb0-46d689bf22d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `AI_engineering` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `AI_engineering`\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN\n",
        "!huggingface-cli login --token $$HUGGINGFACE_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz4WrELLELSP"
      },
      "source": [
        "stramlitã§Huggingfaceã®ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±ã‚’æ‰±ã†ãŸã‚ã«ã€streamlitç”¨ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.streamlitï¼‰ã‚’ä½œæˆã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ã®æƒ…å ±ã‚’æ ¼ç´ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W184-a7qFP0W"
      },
      "outputs": [],
      "source": [
        "# .streamlit/secrets.toml ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ\n",
        "import os\n",
        "import toml\n",
        "\n",
        "# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºä¿\n",
        "os.makedirs('.streamlit', exist_ok=True)\n",
        "\n",
        "# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€\n",
        "secrets = {\n",
        "    \"huggingface\": {\n",
        "        \"token\": os.environ.get(\"HUGGINGFACE_TOKEN\", \"\")\n",
        "    }\n",
        "}\n",
        "\n",
        "# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã‚€\n",
        "with open('.streamlit/secrets.toml', 'w') as f:\n",
        "    toml.dump(secrets, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK0vI_xKELSP"
      },
      "source": [
        "ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã—ã¾ã™ã€‚\n",
        "\n",
        "02_streamlit_appã§ã¯ã€Huggingfaceã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã€åˆå›èµ·å‹•ã«ã¯2åˆ†ç¨‹åº¦æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚\n",
        "\n",
        "ã“ã®å¾…ã¡æ™‚é–“ã‚’åˆ©ç”¨ã—ã¦ã€app.pyã®ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBQyTTWTELSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d277ec-bafb-44ff-8085-8f9b71029cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "å…¬é–‹URL: https://7c69-34-126-123-157.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.126.123.157:8501\u001b[0m\n",
            "\u001b[0m\n",
            "NLTK loaded successfully.\n",
            "2025-04-29 20:31:03.628020: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745958663.862726    2328 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745958663.929285    2328 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-29 20:31:04.436007: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "2025-04-29 20:31:13.890 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "2025-04-29 20:32:11.689 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "2025-04-29 20:32:20.855 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"å…¬é–‹URL: {public_url}\")\n",
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUe7y6NzNxEr"
      },
      "source": [
        "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æ©Ÿèƒ½ã¨ã—ã¦ã¯ã€ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã‚„å±¥æ­´é–²è¦§ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "\n",
        "ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã¯ã€Streamlitã«ã‚ˆã‚‹UIéƒ¨åˆ†ã ã‘ã§ã¯ãªãã€SQLiteã‚’ä½¿ç”¨ã—ãŸãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ä¿å­˜ã‚„LLMã®ãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã—ãŸæ¨è«–ãªã©ã®å‡¦ç†ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "- **`app.py`**: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã€‚ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã€å±¥æ­´é–²è¦§ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã®UIã‚’æä¾›ã—ã¾ã™ã€‚\n",
        "- **`ui.py`**: ãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸ã‚„å±¥æ­´é–²è¦§ãƒšãƒ¼ã‚¸ãªã©ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®UIãƒ­ã‚¸ãƒƒã‚¯ã‚’ç®¡ç†ã—ã¾ã™ã€‚\n",
        "- **`llm.py`**: LLMãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã¨ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’è¡Œã†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚\n",
        "- **`database.py`**: SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¦ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä¿å­˜ãƒ»ç®¡ç†ã—ã¾ã™ã€‚\n",
        "- **`metrics.py`**: BLEUã‚¹ã‚³ã‚¢ã‚„ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãªã©ã€å›ç­”ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚\n",
        "- **`data.py`**: ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã‚’è¡Œã†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚\n",
        "- **`config.py`**: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è¨­å®šï¼ˆãƒ¢ãƒ‡ãƒ«åã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«åï¼‰ã‚’ç®¡ç†ã—ã¾ã™ã€‚\n",
        "- **`requirements.txt`**: ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã«å¿…è¦ãªPythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvm8sWFPELSP"
      },
      "source": [
        "å¾Œç‰‡ä»˜ã‘ã¨ã—ã¦ã€ä½¿ã†å¿…è¦ã®ãªã„ngrokã®ãƒˆãƒ³ãƒãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFJC2TmZELSP"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUXhIzV7ELSP"
      },
      "source": [
        "# 03_FastAPI\n",
        "\n",
        "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€Œ03_FastAPIã€ã«ç§»å‹•ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ejjDLxr3kfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3048bec9-0385-4cd8-c134-7d00b0298771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lecture-ai-engineering/day1/03_FastAPI\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/03_FastAPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f45TDsNzELSQ"
      },
      "source": [
        "å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uv6glCz5a7Z"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfrmE2VmELSQ"
      },
      "source": [
        "ngrokã¨huggigfaceã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€èªè¨¼ã‚’è¡Œã„ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELzWhMFORRIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c31aaa-4d6a-4d10-8d0b-13458d81dad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `AI_engineering` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `AI_engineering`\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN\n",
        "!huggingface-cli login --token $$HUGGINGFACE_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-wztc2CELSQ"
      },
      "source": [
        "ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã—ã¾ã™ã€‚\n",
        "\n",
        "ã€Œ02_streamlit_appã€ã‹ã‚‰ç¶šã‘ã¦ã€Œ03_FastAPIã€ã‚’å®Ÿè¡Œã—ã¦ã„ã‚‹å ´åˆã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒæ¸ˆã‚“ã§ã„ã‚‹ãŸã‚ã€ã™ãã«ã‚µãƒ¼ãƒ“ã‚¹ãŒç«‹ã¡ä¸ŠãŒã‚Šã¾ã™ã€‚\n",
        "\n",
        "ã€Œ03_FastAPIã€ã®ã¿ã‚’å®Ÿè¡Œã—ã¦ã„ã‚‹å ´åˆã¯ã€åˆå›ã®èµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå§‹ã¾ã‚‹ã®ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒçµ‚ã‚ã‚‹ã¾ã§æ•°åˆ†é–“å¾…ã¡ã¾ã—ã‚‡ã†ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "git add ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "QyCwiGi2TBd3",
        "outputId": "e6378676-feb6-46b7-d9fe-7a24febb61ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-16-3d6cfb4a5e4d>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-3d6cfb4a5e4d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    git add .\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meQ4SwISn3IQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d8d8b6f-b403-4424-bec1-28a197ce74eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-29 20:37:56.077761: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745959076.133585    4115 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745959076.166110    4115 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-29 20:37:56.230846: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "ãƒ¢ãƒ‡ãƒ«åã‚’è¨­å®š: google/gemma-2-2b-jpn-it\n",
            "/content/lecture-ai-engineering/day1/03_FastAPI/app.py:134: DeprecationWarning: \n",
            "        on_event is deprecated, use lifespan event handlers instead.\n",
            "\n",
            "        Read more about it in the\n",
            "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
            "        \n",
            "  @app.on_event(\"startup\")\n",
            "FastAPIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å®šç¾©ã—ã¾ã—ãŸã€‚\n",
            "ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªngrokãƒˆãƒ³ãƒãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n",
            "ãƒãƒ¼ãƒˆ8501ã«æ–°ã—ã„ngrokãƒˆãƒ³ãƒãƒ«ã‚’é–‹ã„ã¦ã„ã¾ã™...\n",
            "---------------------------------------------------------------------\n",
            "âœ… å…¬é–‹URL:   https://0884-34-126-123-157.ngrok-free.app\n",
            "ğŸ“– APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ (Swagger UI): https://0884-34-126-123-157.ngrok-free.app/docs\n",
            "---------------------------------------------------------------------\n",
            "(APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚„ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãŸã‚ã«ã“ã®URLã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„)\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m4115\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "load_model_task: ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã‚’é–‹å§‹...\n",
            "ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: cuda\n",
            "config.json: 100% 805/805 [00:00<00:00, 4.42MB/s]\n",
            "model.safetensors.index.json: 100% 24.2k/24.2k [00:00<00:00, 62.6MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.99G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 0.00/241M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/4.99G [00:00<00:53, 92.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   4% 10.5M/241M [00:00<00:03, 66.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/4.99G [00:00<00:50, 98.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  13% 31.5M/241M [00:00<00:01, 105MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 41.9M/4.99G [00:00<00:39, 126MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  22% 52.4M/241M [00:00<00:01, 125MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/4.99G [00:00<00:36, 135MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  30% 73.4M/241M [00:00<00:01, 123MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 83.9M/4.99G [00:00<00:41, 117MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  39% 94.4M/241M [00:00<00:01, 113MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 105M/4.99G [00:00<00:39, 125MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 126M/4.99G [00:01<00:39, 124MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  48% 115M/241M [00:01<00:01, 112MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 147M/4.99G [00:01<00:37, 129MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  57% 136M/241M [00:01<00:00, 117MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 168M/4.99G [00:01<00:38, 126MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  65% 157M/241M [00:01<00:00, 121MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 189M/4.99G [00:01<00:36, 131MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  74% 178M/241M [00:01<00:00, 108MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  83% 199M/241M [00:01<00:00, 116MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 210M/4.99G [00:01<00:43, 109MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  91% 220M/241M [00:01<00:00, 106MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 231M/4.99G [00:02<00:48, 98.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors: 100% 241M/241M [00:02<00:00, 114MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 241M/241M [00:02<00:00, 108MB/s]\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 273M/4.99G [00:02<00:40, 115MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 304M/4.99G [00:02<00:31, 149MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 336M/4.99G [00:02<00:28, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 367M/4.99G [00:02<00:23, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 398M/4.99G [00:02<00:22, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 430M/4.99G [00:02<00:20, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 461M/4.99G [00:03<00:21, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 493M/4.99G [00:03<00:21, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 524M/4.99G [00:03<00:21, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 556M/4.99G [00:03<00:22, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 577M/4.99G [00:03<00:22, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 608M/4.99G [00:03<00:19, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 640M/4.99G [00:03<00:19, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 671M/4.99G [00:04<00:17, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 703M/4.99G [00:04<00:20, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 744M/4.99G [00:04<00:17, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 776M/4.99G [00:07<02:03, 34.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 828M/4.99G [00:07<01:16, 54.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 881M/4.99G [00:07<00:50, 80.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 923M/4.99G [00:07<00:39, 103MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 965M/4.99G [00:07<00:31, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.01G/4.99G [00:07<00:26, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.04G/4.99G [00:08<00:23, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/4.99G [00:08<00:20, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.11G/4.99G [00:08<00:18, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/4.99G [00:08<00:17, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.17G/4.99G [00:08<00:18, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.22G/4.99G [00:08<00:15, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.25G/4.99G [00:08<00:14, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.28G/4.99G [00:08<00:14, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.31G/4.99G [00:09<00:15, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.34G/4.99G [00:09<00:14, 245MB/s]\u001b[At=2025-04-29T20:38:21+0000 lvl=warn msg=\"failed to open private leg\" id=f44f487f7473 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "\n",
            "model-00001-of-00002.safetensors:  28% 1.37G/4.99G [00:11<01:21, 44.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.41G/4.99G [00:11<01:02, 57.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/4.99G [00:11<00:47, 75.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.99G [00:11<00:33, 105MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.51G/4.99G [00:11<00:27, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.55G/4.99G [00:11<00:20, 165MB/s]\u001b[At=2025-04-29T20:38:23+0000 lvl=warn msg=\"failed to open private leg\" id=1d562289e11d privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "\n",
            "model-00001-of-00002.safetensors:  32% 1.59G/4.99G [00:13<00:42, 80.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.64G/4.99G [00:13<00:31, 106MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.67G/4.99G [00:13<00:26, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.70G/4.99G [00:14<00:59, 55.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.72G/4.99G [00:15<01:11, 45.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.77G/4.99G [00:15<00:43, 73.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.82G/4.99G [00:15<00:29, 107MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.86G/4.99G [00:15<00:24, 127MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.91G/4.99G [00:15<00:17, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.95G/4.99G [00:16<00:15, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.99G/4.99G [00:16<00:13, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.03G/4.99G [00:16<00:11, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.08G/4.99G [00:16<00:10, 285MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.12G/4.99G [00:16<00:09, 310MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.16G/4.99G [00:16<00:09, 310MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.20G/4.99G [00:16<00:09, 284MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.24G/4.99G [00:17<00:10, 274MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/4.99G [00:17<00:10, 265MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.31G/4.99G [00:17<00:11, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.35G/4.99G [00:17<00:09, 274MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.38G/4.99G [00:17<00:10, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.41G/4.99G [00:17<00:10, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/4.99G [00:17<00:10, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.47G/4.99G [00:17<00:10, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.51G/4.99G [00:18<00:10, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.55G/4.99G [00:18<00:08, 271MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.58G/4.99G [00:18<00:09, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.61G/4.99G [00:18<00:13, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.65G/4.99G [00:18<00:10, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.69G/4.99G [00:18<00:08, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.74G/4.99G [00:19<00:08, 275MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/4.99G [00:19<00:07, 300MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.82G/4.99G [00:19<00:07, 286MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.85G/4.99G [00:19<00:07, 271MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.88G/4.99G [00:21<00:43, 48.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.92G/4.99G [00:21<00:33, 61.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.95G/4.99G [00:21<00:26, 77.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.99G/4.99G [00:22<00:19, 105MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.02G/4.99G [00:22<00:16, 120MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.05G/4.99G [00:22<00:13, 143MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/4.99G [00:22<00:11, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.11G/4.99G [00:22<00:10, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.15G/4.99G [00:22<00:09, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.18G/4.99G [00:22<00:08, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.21G/4.99G [00:22<00:07, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.24G/4.99G [00:23<00:07, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.27G/4.99G [00:23<00:08, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.31G/4.99G [00:23<00:06, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.34G/4.99G [00:23<00:06, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.38G/4.99G [00:23<00:05, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.41G/4.99G [00:23<00:05, 272MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.44G/4.99G [00:23<00:05, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.47G/4.99G [00:23<00:06, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.50G/4.99G [00:24<00:05, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/4.99G [00:24<00:05, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.57G/4.99G [00:24<00:05, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/4.99G [00:24<00:05, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.63G/4.99G [00:24<00:05, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.66G/4.99G [00:24<00:05, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.69G/4.99G [00:25<00:09, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.71G/4.99G [00:30<01:15, 16.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.75G/4.99G [00:30<00:46, 26.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.81G/4.99G [00:30<00:27, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.85G/4.99G [00:30<00:18, 60.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.89G/4.99G [00:30<00:13, 81.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.93G/4.99G [00:30<00:09, 106MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/4.99G [00:30<00:07, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.02G/4.99G [00:31<00:06, 158MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.05G/4.99G [00:31<00:05, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.08G/4.99G [00:31<00:05, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.11G/4.99G [00:31<00:04, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.14G/4.99G [00:31<00:04, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.17G/4.99G [00:31<00:03, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.20G/4.99G [00:32<00:04, 173MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.26G/4.99G [00:32<00:03, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.29G/4.99G [00:32<00:02, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.33G/4.99G [00:32<00:02, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.38G/4.99G [00:32<00:02, 290MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.41G/4.99G [00:32<00:02, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.45G/4.99G [00:32<00:02, 262MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.48G/4.99G [00:32<00:01, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.51G/4.99G [00:33<00:01, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.54G/4.99G [00:33<00:01, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.57G/4.99G [00:33<00:01, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.60G/4.99G [00:33<00:01, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.63G/4.99G [00:33<00:01, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.67G/4.99G [00:33<00:01, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.70G/4.99G [00:33<00:01, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.73G/4.99G [00:34<00:01, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.77G/4.99G [00:34<00:00, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.81G/4.99G [00:34<00:00, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.87G/4.99G [00:34<00:00, 303MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.91G/4.99G [00:34<00:00, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.94G/4.99G [00:34<00:00, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.99G/4.99G [00:35<00:00, 142MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:35<00:00, 17.69s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  7.65it/s]\n",
            "generation_config.json: 100% 168/168 [00:00<00:00, 1.05MB/s]\n",
            "tokenizer_config.json: 100% 46.9k/46.9k [00:00<00:00, 22.6MB/s]\n",
            "tokenizer.model: 100% 4.24M/4.24M [00:00<00:00, 77.0MB/s]\n",
            "tokenizer.json: 100% 17.5M/17.5M [00:00<00:00, 158MB/s]\n",
            "special_tokens_map.json: 100% 555/555 [00:00<00:00, 3.09MB/s]\n",
            "Device set to use cuda\n",
            "ãƒ¢ãƒ‡ãƒ« 'google/gemma-2-2b-jpn-it' ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸ\n",
            "load_model_task: ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n",
            "èµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8501\u001b[0m (Press CTRL+C to quit)\n",
            "t=2025-04-29T20:41:30+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-5fddad1f-796f-4850-91e9-5126a35a8e61 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "\u001b[32mINFO\u001b[0m:     Shutting down\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
            "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n",
            "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m4115\u001b[0m]\n",
            "\n",
            "ã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ãŒçµ‚äº†ã—ã¾ã—ãŸã€‚\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-1' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 580, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 66, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 69, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 330, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLubjIhbELSR"
      },
      "source": [
        "FastAPIãŒèµ·å‹•ã™ã‚‹ã¨ã€APIã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒé€šä¿¡ã™ã‚‹ãŸã‚ã®URLï¼ˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰ãŒä½œã‚‰ã‚Œã¾ã™ã€‚\n",
        "\n",
        "URLãŒä½œã‚‰ã‚Œã‚‹ã®ã¨åˆã‚ã›ã¦ã€Swagger UIã¨ã„ã†Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãŒä½œã‚‰ã‚Œã¾ã™ã€‚\n",
        "\n",
        "Swagger UIã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã“ã¨ã§ã€APIã®ä»•æ§˜ã‚’ç¢ºèªã§ããŸã‚Šã€APIã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
        "\n",
        "Swagger UIã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€APIã‚’é€šã—ã¦LLMã‚’å‹•ã‹ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgumW3mGELSR"
      },
      "source": [
        "å¾Œç‰‡ä»˜ã‘ã¨ã—ã¦ã€ä½¿ã†å¿…è¦ã®ãªã„ngrokã®ãƒˆãƒ³ãƒãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJymTZio-WPJ"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}